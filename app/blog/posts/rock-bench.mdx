---
title: "Recursions till that's not The Rock'"
date: "2025-01-24"
summary: "Testing image editing model resilience across 100 recursive Dwaynes."
---

I regularly work with image editing models in my day-to-day, they're fantastic, but they generally fall apart if you edit the edit of the edit's edit.

Earlier this year, [u/Foreign_Builder_2238](https://www.reddit.com/u/Foreign_Builder_2238) demonstrated this by asking ChatGPT to endlessly recreate a photo of Dwayne 'The Rock' Johnson —'Create an exact replica of this image, don't change a thing.' I put the modern image editors through that same recursive abuse (Nano Banana Pro, SeeDream 4, Qwen, and friends) to see how they unravel when looping their own outputs 100 times.

The findings were both interesting and ridiculous, with all the models tested behaving in slightly different ways. To add a veneer of scientific rigour, I calculated the structural similarity index for each generated image compared with the original. These are graphed for each model below .

The SSIM trend is interesting, but what matters more, I think, is how many recursions it takes before it isn't The Rock anymore. So, this project also attempts to define a **Recursions till that's not The Rock** score per model.


## GPT-Image1

The original reddit post was 7 months prior to writing this, lets check in on how things have changed.

<LocalVideo
  src="/videos/gpt_evolution.mp4?v=2"
  caption="Quite disappointing really. Almost immediately degrades to static, then slightly recovers before falling to pieces. This was the worst performing model in the test."
/>

<ModelChart activeModel="gpt" />

## GPT-Image1-mini

What about GPT's mini bretheren

<LocalVideo
  src="/videos/gptmini_evolution.mp4?v=4"
  caption="The only model that didn't degrade into noise, and my personal favorite. Appears to show that mini isn't just 'smaller' and there are more substantial differences at play. Interestingly, across several tests it consistently ended up with a variation of a vampiric white guy... Coincidence?"
/>

<ModelChart activeModel="gptMini" />

## Nano Banana Pro

Currently the touted SOTA of image editing models, how does it degrade?

<LocalVideo
  src="/videos/nano_banana_pro_evolution.mp4?v=2"
  caption="The results get quite noisy by 10 recursions and devolves from there into fractals and eventually into an LCD TV victim of Wii Sports."
/>

<ModelChart activeModel="nanoBananaPro" />

## SeeDream 4

Currently the runner-up to Nano Banana Pro in the leaderboards, the model typically performs quite well with photographic edits.

<LocalVideo
  src="/videos/seedream_evolution.mp4?v=2"
  caption="The only model tested that got… hairy? Also notable for spontaneous suspenders, wings, and a ginger man somehow more jacked than Dwayne."
/>

<ModelChart activeModel="seedream" />

## Qwen Image Edit

Highly trainable model which has recently been gaining popularity on the release of a few nice fine tunes.

<LocalVideo
  src="/videos/qwen_evolution.mp4?v=2"
  caption="A fairly unremarkable descent into blotchy green noise distinguished only by refreshed facial hair and luscious lips."
/>

<ModelChart activeModel="qwen" />

## Nano Banana

A fantastic model, only recently overshadowed by the pro upgrade.

<LocalVideo
  src="/videos/nanobana_evolution.mp4?v=2"
  caption="The only model with significant Dwaynian motion, where the subject slides off to the side while turning to ectoplasm."
/>

<ModelChart activeModel="nanoBanana" />

## Flux Kontext Pro

The model that proved the usefulness of editing models, it is over a year old now.

<LocalVideo
  src="/videos/flux_evolution.mp4?v=2"
  caption="Pretty good! It performs the best of the models tested from an SSIM perspective, but the results still trend to noise and abrupt white dudes."
/>

<ModelChart activeModel="flux" />

## All Models Compared

<MegaChart />

## What can we learn from this?

Not much with a sample size of 1, and a below average IQ.
